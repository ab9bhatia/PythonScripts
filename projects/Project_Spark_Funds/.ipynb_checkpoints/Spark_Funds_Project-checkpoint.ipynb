{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investment Case Group Project\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Prerequisites/ Downloads/ Project Information](http://nbviewer.jupyter.org/github/ab9bhatia/PythonScripts/blob/master/projects/Project_Spark_Funds/Spark_Funds_Information.ipynb)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries and set required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numpy : Numerical & Scientific computing\n",
    "import numpy as np\n",
    "\n",
    "# pandas : for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# os : used for operating system dependent functionality\n",
    "import os\n",
    "\n",
    "# re : to handle regular expresiions\n",
    "import re\n",
    "\n",
    "# matplotlib : data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# set the backend of matplotlib to the 'inline' backend\n",
    "%matplotlib inline \n",
    "\n",
    "from IPython.display import Image # To view image from location/url\n",
    "\n",
    "pd.options.mode.chained_assignment = None #set it to None to remove SettingWithCopyWarning\n",
    "pd.options.display.float_format = '{:.2f}'.format #set it to convert scientific noations such as 4.225108e+11 to 422510842796.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input & Output Directory Path\n",
    "#### IMPORTANT: Replace inputDir & outDir path with your directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companies.txt\t8965.0 KB\n",
      "mapping.csv\t23.0 KB\n",
      "rounds2.csv\t11846.0 KB\n"
     ]
    }
   ],
   "source": [
    "inputDir = './data/'\n",
    "outDir = './outDir/'\n",
    "file1 = 'companies.txt'\n",
    "file2 = 'rounds2.csv'\n",
    "file3 = 'mapping.csv'\n",
    "encoding = 'ANSI'\n",
    "#and encoding of ANSI,ISO 3166-1 alpha-3 'iso-8859-1'\n",
    "\n",
    "# List files present in inputDir\n",
    "for fileName in os.listdir(inputDir):\n",
    "    print(fileName+'\\t'+str(round((os.path.getsize(inputDir+fileName)/1000),0))+' KB')\n",
    "\n",
    "dynamic = False\n",
    "\n",
    "# dynamic = True\n",
    "# Note for the English Speaking Countries if you want to dynamically get the information from MySQL > MySQl > world database > \n",
    "# country & country language table.\n",
    "# Run command as mentioned in prerequisite : conda install -c anaconda mysql-connector-python¶\n",
    "# Run this sql on world db > INSERT INTO COUNTRYLANGUAGE VALUES('IND','English','T',4.5)\n",
    "\n",
    "# dynamic = False\n",
    "# Manually a column will be added(by referring pdf) in top9 dataframe called IsOfficialEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading datasets into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.read_csv(inputDir+file1,sep='\\t',encoding= encoding)\n",
    "rounds2 = pd.read_csv(inputDir+file2,encoding= encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get some insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1.1\n",
    "#### Q1. How many unique companies are present in rounds2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .nunique() wil give Unique count(excludes NA), use .lower() , to bring all values in lower case\n",
    "# if you use .count(), it will only give total no of rows without excluding duplicates)\n",
    "\n",
    "rounds2.company_permalink.str.lower().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. How many unique companies are present in companies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.permalink.str.lower().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. In the companies data frame, which column can be used as the unique key for each company? Write the name of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nunique() will give unique values for each column, column with maximum unique counts\n",
    "#(or where total unique rows = total values in columns) can be considered as unique column#### \n",
    "\n",
    "print(list(companies.nunique().sort_values(ascending=False).iloc[0:1].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. Are there any companies in the rounds2 file which are not  present in companies ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the existacce of a unique column of dataframe1 in unique column of dataframe2\n",
    "diff = rounds2[rounds2['company_permalink'].str.lower().isin(companies['permalink'].str.lower())== False]\n",
    "print('Yes' if diff.company_permalink.count() >= 0 else 'No')\n",
    "diff\n",
    "\n",
    "# Note : You may not get the difference in R, because of the different encoding.\n",
    "# Python >> encoding='iso-8859-1'\n",
    "# R      >> encoding='utf-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. Merge the two data frames so that all  variables (columns)  in the companies frame are added to the rounds2 data frame. Name the merged frame master_frame. How many observations are present in master_frame ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower() the key columns of both dataframes, so they can match in case of diffence in case.\n",
    "companies['permalink'] = companies['permalink'].str.lower()\n",
    "rounds2['company_permalink'] = rounds2['company_permalink'].str.lower()\n",
    "master_frame = pd.merge(left = companies,right = rounds2, how ='inner', left_on='permalink',right_on='company_permalink')\n",
    "print('\\nNumber of Records: ',master_frame.count()[0])\n",
    "\n",
    "# From here onwards we will work with master_frame only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Rows from master_frame where raised_amount_usd is null\n",
    "# filter criteria\n",
    "raised_amount_usd_isNull = master_frame[master_frame.raised_amount_usd.isnull()] \n",
    "master_frame = master_frame.drop(raised_amount_usd_isNull.index)\n",
    "\n",
    "print('\\nNumber of Records Dropped: ',raised_amount_usd_isNull.count()[0])\n",
    "print('\\nNumber of Records: ',master_frame.count()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function to store dataframe at user location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a function to wite(.csv) a file to the user location.\n",
    "def writeDF(dataframe,filename,dir_path):\n",
    "    '''\n",
    "    dataframe : Dataframe name\n",
    "    filename  : Give csv file name\n",
    "    dir_path  : Directory path where the file should be written\n",
    "    '''\n",
    "    dataframe.to_csv(path_or_buf = outDir+filename+'.csv')\n",
    "    size = str(round((os.path.getsize(outDir+filename+'.csv')/1000),1))\n",
    "    print('File: '+filename+'.csv created at '+outDir+ '\\nSize of file :\\t'+size+ ' KB' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Data(master_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing master_frame dataframe at user location, we can use this dataframe while building plots.\n",
    "writeDF(master_frame,'master_frame',outDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 2: Funding Type Analysis\n",
    "### Table 2.1 ( Average Values of Investments for Each of these Funding Types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function to get the avg_funding_amount for any Funding type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining a function to get average funding amount for any funding type.\n",
    "def avg_funding_amount(funding_type):\n",
    "    return round(master_frame[master_frame['funding_round_type']==funding_type]['raised_amount_usd'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1/2/3/4. Average funding amount of different funding type ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "venture = avg_funding_amount('venture')\n",
    "angel = avg_funding_amount('angel')\n",
    "seed = avg_funding_amount('seed')\n",
    "private_equity = avg_funding_amount('private_equity')\n",
    "\n",
    "print('venture\\t\\t' ,avg_funding_amount('venture'))\n",
    "print('angel\\t\\t' ,avg_funding_amount('angel'))\n",
    "print('seed\\t\\t' ,avg_funding_amount('seed'))\n",
    "print('private_equity\\t' ,avg_funding_amount('private_equity'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. Considering that Spark Funds wants to invest between 5 to 15 million USD per  investment round, which investment type is the most suitable for them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check from the last step that only venture funding type lies between 5 to 15 million.\n",
    "# Alternatively we can find the funding type through below code:\n",
    "## [['']] double brackets or (.reset_index()) are used to keep the dataframe , if we use [''], it will be converted into series\n",
    "\n",
    "# Aggregate 'raised_amount_usd' on each 'funding_round_type' and check if 'raised_amount_usd' is between 5 to 15 million USD\n",
    "most_suitable = master_frame.groupby(by='funding_round_type')[['raised_amount_usd']].mean()\n",
    "most_suitable = most_suitable[(most_suitable.raised_amount_usd >= 5000000) & (most_suitable.raised_amount_usd <= 15000000)]\n",
    "most_suitable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('So most suitable Funding Round Type is '+str(list(most_suitable.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the master_frame dataset based on the above conditions(most_suitable funding_round_type)\n",
    "master_frame_filtered = master_frame[master_frame.funding_round_type == most_suitable.index[0]]\n",
    "\n",
    "print('\\nNumber of Records: ',master_frame_filtered.count()[0])\n",
    "master_frame_filtered.head(3)\n",
    "\n",
    "# Now master_frame_filtered contains the data where funding_round_type ='venture' & raised_amount_usd between 5 to 15 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 3: Country Analysis\n",
    "### Table 3.1 ( Analysing the Top 3 English-Speaking Countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top9 = master_frame_filtered.groupby('country_code')['raised_amount_usd'].sum().sort_values(ascending=False).reset_index()[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add a new column identifier, IsOfficialEN in top9 dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the requirement is to fetch top 3 countries from top 9 dataframe where official language is English, we will fetch this \n",
    "# information from MySQl > world database > country & country language table. Alternatively we can check this information\n",
    "# from the pdf provided, but there we have to hardcode the information.\n",
    "\n",
    "if dynamic:\n",
    "    import mysql.connector as con\n",
    "    db_connection = con.connect(host='localhost', database='world', user='root', password='mysql@123')\n",
    "    query = 'select code,name from country where code in(SELECT countrycode FROM COUNTRYLANGUAGE WHERE LANGUAGE=%s AND ISOFFICIAL=%s)'\n",
    "    countryEN =  pd.read_sql(sql =query,con =db_connection,params=['English','T'])\n",
    "    top9['IsOfficialEN'] = top9.country_code.isin(countryEN['code'])\n",
    "else:\n",
    "    top9['IsOfficialEN'] = [True,False,True,True,True,False,False,False,False]\n",
    "    # these values are added based on the pdf link of English Speaking Countries \n",
    "    #http://www.emmir.org/fileadmin/user_upload/admission/Countries_where_English_is_an_official_language.pdf\n",
    "    \n",
    "top9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Data(top9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing top9 dataframe at user location, we can use this dataframe while building plots.\n",
    "writeDF(top9,'top9',outDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1/2/3. Top/Second/Third English speaking country ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3 = top9[top9.IsOfficialEN].iloc[0:3,0:2].reset_index()\n",
    "top = top3.country_code[0]\n",
    "second = top3.country_code[1]\n",
    "third = top3.country_code[2]\n",
    "\n",
    "print('top\\t',top)\n",
    "print('second\\t',second)\n",
    "print('third\\t',third)\n",
    "top3.iloc[0:3,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter master_frame_filtered dataset based on top 3 english speaking countries\n",
    "top3_data = master_frame_filtered.loc[master_frame_filtered.country_code.isin(top3.country_code)]\n",
    "print('\\nNumber of Records: ',top3_data.count()[0])\n",
    "top3_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 4: Sector Analysis 1\n",
    "### Table 5.1 ( Sector-wise Investment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first string before the | will be considered the primary sector.\n",
    "# Add the new column in master_frame_filtered dataframe named as 'primary_sector'\n",
    "top3_data['primary_sector'] = top3_data['category_list'].str.split('|').str.get(0)\n",
    "\n",
    "print('\\nNumber of Records: ',top3_data.count()[0])\n",
    "top3_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping =  pd.read_csv(inputDir+file3,encoding='iso-8859-1') # Use 'iso-8859-1' for accented characters\n",
    "print('\\nNumber of Records in mapping: ',mapping.shape[0]) # shape includes NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean Mapping.csv(replace 0 with na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are multiple records in the dataset column category_list where 'na' is replaced by 0, so we have to replace 0 with na,\n",
    "# we have to make sure if data contains 2.0 or v3.0 we should not replace it.\n",
    "# '.*' is for zero or more occurances before 0, '.+ is for one or more occurance after 0.\n",
    "\n",
    "regex = (mapping.category_list.str.contains('[.*0]')==True) &  (mapping.category_list.str.endswith('0')==False)\n",
    "mapping_cleaned = mapping.copy()\n",
    "mapping_cleaned.loc[regex,'category_list'] = mapping_cleaned.loc[regex,'category_list'].replace('0','na',regex=True)\n",
    "mapping_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.melt(mapping_cleaned, id_vars=['category_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function(demap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining function demap, which will convert data in mapping dataframe above to two columns output.\n",
    "def demap(df,outColName):\n",
    "    l = list()\n",
    "    c = int(df.count().sort_values(ascending=False)[0])\n",
    "    for i in range(c):\n",
    "        for col_name in df.columns:\n",
    "            if df[col_name][i]==1:\n",
    "               l.append(col_name)\n",
    "    df2 = df.copy()\n",
    "    df2[outColName] = l\n",
    "    return df2.iloc[:,[0,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Map Category List with Main Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_new = demap(mapping_cleaned,'main_sector')\n",
    "mapping_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge Top3 data with mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_data_sector_wise = pd.merge(left=top3_data, right=mapping_new,left_on='primary_sector',right_on='category_list')\n",
    "# Drop unnecessary columns\n",
    "top3_data_sector_wise.drop(labels=['category_list_x', 'category_list_y'],axis=1, inplace=True)\n",
    "\n",
    "print('\\nNumber of Records: ',top3_data_sector_wise.count()[0])\n",
    "top3_data_sector_wise.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Data (top3_data_sector_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing master_frame_sector_wise dataframe at user location\n",
    "# top3_data_sector_wise :: Contains the data for top3 english speaking countries where a particular funding type falling \n",
    "#within the 5-15 million USD range.\n",
    "\n",
    "writeDF(top3_data_sector_wise,'top3_data_sector_wise',outDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 5: Sector Analysis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created three separate data frames D1, D2 and D3 for each of the three english countries containing the observations of funding type falling within the 5-15 million USD range.\n",
    "The three data frames should contain:\n",
    "1. All the columns of the master_frame along with the primary sector and the main sector\n",
    "2. The total number (or count) of investments for each main sector in a separate column\n",
    "3. The total amount invested in each main sector in a separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USA\n",
    "D1 = top3_data_sector_wise[top3_data_sector_wise['country_code']==top]\n",
    "\n",
    "#GBR\n",
    "D2 = top3_data_sector_wise[top3_data_sector_wise['country_code']==second]\n",
    "\n",
    "#IND\n",
    "D3 = top3_data_sector_wise[top3_data_sector_wise['country_code']==third]\n",
    "\n",
    "D1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q1. Total number of Investments (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D1.count()[0])\n",
    "print(D2.count()[0])\n",
    "print(D3.count()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Q2. Total amount of investment (USD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D1.raised_amount_usd.sum())\n",
    "print(D2.raised_amount_usd.sum())\n",
    "print(D3.raised_amount_usd.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define function to get top sectors count and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSector(dataset,n,identifier):\n",
    "    '''\n",
    "    dataset     :: datframe\n",
    "    n           :: n represents nth order, 0 for top, 1 for second top and so on.\n",
    "    identifier  :: identifier = 'count' to get the count, identifier = 'name' to get the sector name.\n",
    "    '''\n",
    "    if identifier == 'name':\n",
    "        return (dataset.groupby(by='main_sector')['main_sector'].count().sort_values(ascending=False).index[n])\n",
    "    elif identifier == 'count':\n",
    "        return (dataset.groupby(by='main_sector')['main_sector'].count().sort_values(ascending=False)[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Top sector (based on count of investments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_sec0_name = getSector(dataset=D1,n=0,identifier='name')\n",
    "D2_sec0_name = getSector(D2,0,'name')\n",
    "D3_sec0_name = getSector(D3,0,'name')\n",
    "\n",
    "print('D1_sec0_name : ',D1_sec0_name,'\\nD2_sec0_name : ',D2_sec0_name,'\\nD3_sec0_name : ',D3_sec0_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. Second-best sector (based on count of investments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_sec1_name = getSector(D1,1,'name')\n",
    "D2_sec1_name = getSector(D2,1,'name')\n",
    "D3_sec1_name = getSector(D3,1,'name')\n",
    "\n",
    "print('D1_sec1_name : ',D1_sec1_name,'\\nD2_sec1_name : ',D2_sec1_name,'\\nD3_sec1_name : ',D3_sec1_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. Third-best sector (based on count of investments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_sec2_name = getSector(D1,2,'name')\n",
    "D2_sec2_name = getSector(D2,2,'name')\n",
    "D3_sec2_name = getSector(D3,2,'name')\n",
    "\n",
    "print('D1_sec2_name : ',D1_sec2_name,'\\nD2_sec2_name : ',D2_sec2_name,'\\nD3_sec2_name : ',D3_sec2_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. Number of investments in the top sector (refer to point 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_sec0_count = getSector(D1,0,'count')\n",
    "D2_sec0_count = getSector(D2,0,'count')\n",
    "D3_sec0_count = getSector(D3,0,'count')\n",
    "\n",
    "print('D1_sec0_count : ',D1_sec0_count,'\\nD2_sec0_count : ',D2_sec0_count,'\\nD3_sec0_count : ',D3_sec0_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. Number of investments in the second-best sector (refer to point 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_sec1_count = getSector(D1,1,'count')\n",
    "D2_sec1_count = getSector(D2,1,'count')\n",
    "D3_sec1_count = getSector(D3,1,'count')\n",
    "\n",
    "print('D1_sec1_count : ',D1_sec1_count,'\\nD2_sec1_count : ',D2_sec1_count,'\\nD3_sec1_count : ',D3_sec1_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8. Number of investments in the third-best sector (refer to point 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_sec2_count = getSector(D1,2,'count')\n",
    "D2_sec2_count = getSector(D2,2,'count')\n",
    "D3_sec2_count = getSector(D3,2,'count')\n",
    "\n",
    "print('D1_sec2_count : ',D1_sec2_count,'\\nD2_sec2_count : ',D2_sec2_count,'\\nD3_sec2_count : ',D3_sec2_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9. For the top sector count-wise (point 3), which company received the highest investment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframes by top-sector names(Q3), then group by company name and sum the raised_amount_usd, then fetch highest value\n",
    "D1_com0_invt = D1[D1.main_sector == D1_sec0_name].groupby(by='name')['raised_amount_usd'].sum().sort_values(ascending=False).index[0]\n",
    "D2_com0_invt = D2[D2.main_sector == D2_sec0_name].groupby(by='name')['raised_amount_usd'].sum().sort_values(ascending=False).index[0]\n",
    "D3_com0_invt = D3[D3.main_sector == D3_sec0_name].groupby(by='name')['raised_amount_usd'].sum().sort_values(ascending=False).index[0]\n",
    "\n",
    "print('D1_com0_invt : ',D1_com0_invt,'\\nD2_com0_invt : ',D2_com0_invt,'\\nD3_com0_invt : ',D3_com0_invt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10. For the second-best sector count-wise (point 4), which company received the highest investment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_com1_invt = D1[D1.main_sector == D1_sec1_name].groupby(by='name')['raised_amount_usd'].sum().sort_values(ascending=False).index[1]\n",
    "D2_com1_invt = D2[D2.main_sector == D2_sec1_name].groupby(by='name')['raised_amount_usd'].sum().sort_values(ascending=False).index[1]\n",
    "D3_com1_invt = D3[D3.main_sector == D3_sec1_name].groupby(by='name')['raised_amount_usd'].sum().sort_values(ascending=False).index[1]\n",
    "\n",
    "print('D1_com1_invt : ',D1_com1_invt,'\\nD2_com1_invt : ',D2_com1_invt,'\\nD3_com1_invt : ',D3_com1_invt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 6: Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q1. A plot showing the fraction of total investments (globally) in venture, seed, and private equity, and the average amount of investment in each funding type. This chart should make it clear that a certain funding type (FT) is best suited for Spark Funds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_funding_round_type = ['venture','seed','private_equity']\n",
    "plot_frame = master_frame.loc[master_frame.funding_round_type.isin(selected_funding_round_type)]\n",
    "plot_frame = plot_frame.groupby('funding_round_type')['raised_amount_usd'].mean().sort_values(ascending=True).reset_index()\n",
    "#plot_frame_sum = plot_frame.groupby('funding_round_type')['raised_amount_usd'].sum().sort_values(ascending=True).reset_index()\n",
    "\n",
    "cond = ((plot_frame.raised_amount_usd >= 5000000) & (plot_frame.raised_amount_usd <= 15000000))\n",
    "\n",
    "#x_sum = range(len(plot_frame_sum.funding_round_type))\n",
    "#y_sum = plot_frame_sum.raised_amount_usd/ 1000000\n",
    "\n",
    "x = range(len(plot_frame.funding_round_type))\n",
    "y = plot_frame.raised_amount_usd/ 1000000\n",
    "y1 = y[cond]\n",
    "y2 = y[~cond]\n",
    "x1 = list(y1.index)\n",
    "x2 = list(y2.index)\n",
    "\n",
    "#plt.subplot(1,1,1)\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "# Bar plot\n",
    "#plt.bar(x,y, color=cond.map({True: 'g', False: 'k'}),label ='Suitable' )\n",
    "plt.bar(x1,y1, color='g',label ='Suitable' )\n",
    "plt.bar(x2,y2, color='k',label ='Not Suitable' )\n",
    "\n",
    "\n",
    "# Title\n",
    "plt.title('Most Suitable Funding Type')\n",
    "\n",
    "# Labels\n",
    "plt.xlabel('Funding Round Type')\n",
    "plt.ylabel('Average Raised Amount Used in Million(s)')\n",
    "\n",
    "# Ticks\n",
    "plt.xticks(x, plot_frame.funding_round_type)\n",
    "\n",
    "# Horizontal Line\n",
    "plt.axhline(y=5, color='b', linestyle='-',alpha = 0.5)\n",
    "plt.text(max(x)+.7, 5,'5 Million')\n",
    "plt.axhline(y=15, color='b', linestyle='-',alpha = 0.5)\n",
    "plt.text(max(x)+.7, 15,'15 Million')\n",
    "\n",
    "# Add Values to the bar\n",
    "for i in x:\n",
    "    plt.text(x[i]-.1,y[i]+.75,round(y[i],2))\n",
    "\n",
    "# Legend\n",
    "plt.legend()\n",
    "\n",
    "# Save as image\n",
    "plt.savefig(outDir+'Funding_Type.png',bbox_inches=\"tight\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = outDir + \"Tableau/1 FundingType.png\", width=980, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q2. A plot showing the top 9 countries against the total amount of investments of funding type FT. This should make the top 3 countries (Country 1, Country 2, and Country 3) very clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = outDir + \"Tableau/2 Top 9 Countries.png\", width=900, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. A plot showing the number of investments in the top 3 sectors of the top 3 countries on one chart (for the chosen investment type FT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = outDir + \"Tableau/3 Top 3 Sectors.png\", width=1000, height=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
