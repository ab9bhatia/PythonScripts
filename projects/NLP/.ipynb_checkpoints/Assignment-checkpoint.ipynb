{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ab9bh\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\ab9bh\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import gzip, os, pickle # gzip for reading the gz files, pickle to save/dump trained model \n",
    "import _pickle as cPickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "wsj = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(27)\n",
    "train_set, test_set = train_test_split(wsj,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95647"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['By',\n",
       " 'Tuesday',\n",
       " 'night',\n",
       " ',',\n",
       " 'television',\n",
       " 'stations',\n",
       " 'were',\n",
       " 'carrying',\n",
       " 'new',\n",
       " 'ads']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12072\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Since', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('park', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('only', 'RB'),\n",
       " ('1,500', 'CD'),\n",
       " ('spaces', 'NNS'),\n",
       " (',', ','),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Christopher', 'NNP'),\n",
       " ('thinks', 'VBZ'),\n",
       " ('0', '-NONE-'),\n",
       " ('backers', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('playing', 'VBG'),\n",
       " ('some', 'DT'),\n",
       " ('fiscal', 'JJ'),\n",
       " ('``', '``'),\n",
       " ('games', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('voters', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(27)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1 = 'Android is a mobile operating system developed by Google.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "#tagged_seq = Viterbi(test_tagged_words)\n",
    "tagged_seq = Viterbi(test1)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  69.37051057815552\n",
      "[('Since', 'IN'), ('the', 'DT'), ('new', 'JJ'), ('park', 'NN'), ('will', 'MD'), ('have', 'VB'), ('only', 'RB'), ('1,500', 'CD'), ('spaces', 'NNS'), (',', ','), ('Mr.', 'NNP'), ('Christopher', 'NNP'), ('thinks', 'VBZ'), ('0', '-NONE-'), ('backers', 'NNS'), ('are', 'VBP'), ('playing', 'VBG'), ('some', 'DT'), ('fiscal', 'JJ'), ('``', '``'), ('games', 'CC'), (\"''\", 'CC'), ('of', 'IN'), ('their', 'PRP$'), ('own', 'JJ'), ('with', 'IN'), ('the', 'DT'), ('voters', 'NNS'), ('.', '.'), ('The', 'DT'), ('financial-services', 'JJ'), ('company', 'NN'), ('will', 'MD'), ('pay', 'VB'), ('0.82', 'CD'), ('share', 'NN'), ('for', 'IN'), ('each', 'DT'), ('Williams', 'NNP'), ('share', 'NN'), ('.', '.'), ('The', 'DT'), ('forthcoming', 'CC'), ('maturity', 'NN'), ('in', 'IN'), ('November', 'NNP'), ('of', 'IN'), ('a', 'DT'), ('10-year', 'JJ'), ('Japanese', 'JJ'), ('government', 'NN'), ('yen-denominated', 'CC'), ('bond', 'NN'), ('issue', 'NN'), ('valued', 'VBN'), ('*', '-NONE-'), ('at', 'IN'), ('about', 'IN'), ('$', '$'), ('16', 'CD'), ('billion', 'CD'), ('*U*', '-NONE-'), ('has', 'VBZ'), ('prompted', 'VBN'), ('speculation', 'NN'), ('*ICH*-2', '-NONE-'), ('in', 'IN'), ('the', 'DT'), ('market', 'NN'), ('that', 'IN'), ('investors', 'NNS'), ('redeeming', 'CC'), ('the', 'DT'), ('bonds', 'NNS'), ('will', 'MD'), ('diversify', 'VB'), ('into', 'IN'), ('dollar-denominated', 'JJ'), ('instruments', 'NNS'), (',', ','), ('according', 'VBG'), ('to', 'TO'), ('Mr.', 'NNP'), ('Madison', 'NNP'), ('.', '.'), ('The', 'DT'), ('government', 'NN'), (\"'s\", 'POS'), ('construction', 'NN'), ('spending', 'NN'), ('figures', 'NNS'), ('contrast', 'NN'), ('with', 'IN'), ('a', 'DT'), ('report', 'NN'), ('issued', 'VBN'), ('*', '-NONE-'), ('earlier', 'JJR'), ('in', 'IN'), ('the', 'DT'), ('week', 'NN'), ('by', 'IN'), ('McGraw-Hill', 'NNP'), ('Inc.', 'NNP'), (\"'s\", 'POS'), ('F.W.', 'CC'), ('Dodge', 'NNP'), ('Group', 'NNP'), ('.', '.'), ('Last', 'JJ'), ('week', 'NN'), (',', ','), ('Miami-based', 'JJ'), ('Carnival', 'NNP'), ('disclosed', 'VBD'), ('that', 'IN'), ('Waertsilae', 'NNP'), ('Marine', 'NNP'), ('Industries', 'NNPS'), (',', ','), ('the', 'DT'), ('Finnish', 'JJ'), ('shipyard', 'NN'), ('that', 'IN'), ('*T*-1', '-NONE-'), ('is', 'VBZ'), ('building', 'VBG'), ('Carnival', 'NNP'), (\"'s\", 'POS'), ('new', 'JJ'), ('cruise', 'NN'), ('ships', 'NNS'), (',', ','), ('planned', 'VBN'), ('*-2', '-NONE-'), ('to', 'TO'), ('file', 'VB'), ('for', 'IN'), ('bankruptcy', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "print(tagged_seq)\n",
    "#print(test_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('``', '``'), (('games', 'CC'), ('games', 'NNS'))],\n",
       " [('games', 'NNS'), ((\"''\", 'CC'), (\"''\", \"''\"))],\n",
       " [('The', 'DT'),\n",
       "  (('financial-services', 'JJ'), ('financial-services', 'NNS'))],\n",
       " [('The', 'DT'), (('forthcoming', 'CC'), ('forthcoming', 'JJ'))],\n",
       " [('a', 'DT'), (('10-year', 'JJ'), ('10-year', 'CD'))],\n",
       " [('government', 'NN'),\n",
       "  (('yen-denominated', 'CC'), ('yen-denominated', 'JJ'))],\n",
       " [('at', 'IN'), (('about', 'IN'), ('about', 'RB'))],\n",
       " [('investors', 'NNS'), (('redeeming', 'CC'), ('redeeming', 'VBG'))],\n",
       " [('figures', 'NNS'), (('contrast', 'NN'), ('contrast', 'VBP'))],\n",
       " [('report', 'NN'), (('issued', 'VBN'), ('issued', 'VBD'))],\n",
       " [('*', '-NONE-'), (('earlier', 'JJR'), ('earlier', 'RBR'))],\n",
       " [(\"'s\", 'POS'), (('F.W.', 'CC'), ('F.W.', 'NNP'))],\n",
       " [('shipyard', 'NN'), (('that', 'IN'), ('that', 'WDT'))],\n",
       " [(',', ','), (('planned', 'VBN'), ('planned', 'VBD'))]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
