{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec using NLTK/Glove/GoogleNews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version 1.12.1\n",
      "Pandas Version 0.20.3\n",
      "Tensorflow Version 1.1.0\n",
      "Keras Version 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Numpy Version '+np.__version__)\n",
    "import pandas as pd\n",
    "print('Pandas Version '+pd.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "print('Tensorflow Version '+tf.__version__)\n",
    "from IPython.display import Image # To view image from location/url\n",
    "import keras\n",
    "print('Keras Version '+keras.__version__)\n",
    "import nltk\n",
    "import logging\n",
    "import multiprocessing\n",
    "import re\n",
    "import os\n",
    "import gensim\n",
    "from gensim.corpora import WikiCorpus\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from nltk.corpus import brown, movie_reviews, treebank\n",
    "#nltk.download('brown')\n",
    "#nltk.download('movie_reviews')\n",
    "#nltk.download('treebank')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Input & Output files path\n",
    "inputDir = \"./data/\"\n",
    "outputDir = \"./data/outDir/\"\n",
    "inputDir_BigFiles = \"E:/BigFiles/\"\n",
    "outputDir_Bigfiles = \"E:/BigFiles/outDir/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NLTK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown corpus model saved at ./data/outDir/\n",
      "Size of file :19197.8 KB\n"
     ]
    }
   ],
   "source": [
    "brown_model = Word2Vec(brown.sents())\n",
    "movie_reviews_model = Word2Vec(movie_reviews.sents())\n",
    "treebank_model = Word2Vec(treebank.sents())\n",
    "brown_model.save(outputDir+\"brown_model\")\n",
    "size = str(round((os.path.getsize(outputDir+'brown_model')/1000),1))\n",
    "print('Brown corpus model saved at '+outputDir+ '\\nSize of file :'+size+ ' KB' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test NLTK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('care', 0.9140259027481079), ('chance', 0.9021503925323486), ('job', 0.8922946453094482), ('trouble', 0.8632405996322632), ('easy', 0.860753059387207)]\n",
      "cereal\n"
     ]
    }
   ],
   "source": [
    "# Brown\n",
    "print(brown_model.most_similar('money', topn=5))\n",
    "#find the odd one out\n",
    "print (brown_model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "#vector representation of word human\n",
    "#print (brown_model[\"human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('him', 0.7941465377807617), ('someone', 0.7558401823043823), ('sleep', 0.7459496259689331), ('attention', 0.7414337396621704), ('brain', 0.737573504447937)]\n",
      "movie\n"
     ]
    }
   ],
   "source": [
    "# Movie Reviews\n",
    "print(movie_reviews_model.most_similar('money', topn=5))\n",
    "#find the odd one out\n",
    "print (movie_reviews_model.doesnt_match(\"girl boy her movie\".split()))\n",
    "#vector representation of word human\n",
    "#print (movie_reviews_model[\"human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all', 0.9999011158943176), ('only', 0.9998963475227356), ('new', 0.9998949766159058), ('some', 0.999890923500061), (\"'\", 0.9998877048492432)]\n",
      "money\n"
     ]
    }
   ],
   "source": [
    "# Treebank\n",
    "print(treebank_model.most_similar('money', topn=5))\n",
    "#find the odd one out\n",
    "print (treebank_model.doesnt_match(\"financial money earning fat\".split()))\n",
    "#vector representation of word human\n",
    "#print (treebank_model[\"human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(inp, out, type=0):\n",
    "    '''\n",
    "    inp  : Input Dataset\n",
    "    out  : Output Model\n",
    "    type : 0(default) for CBOW & 1 for Skipgram\n",
    "    '''\n",
    "    logger = logging.getLogger(\"word2vect-training\")\n",
    "    logging.basicConfig(format=\"%(asctime)s:%(levelname)s:%(message)s\")\n",
    "    logging.root.setLevel(level=logging.INFO)\n",
    "    \n",
    "    model = Word2Vec(LineSentence(inp), size=100, window=5,min_count=5,workers=multiprocessing.cpu_count(),sg=type)\n",
    "    model.init_sims(replace = True)\n",
    "    model.save(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove model size :171.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert glove_input_file in GloVe format into word2vec_output_file in word2vec format.\n",
    "gensim.scripts.glove2word2vec.glove2word2vec(glove_input_file = inputDir_BigFiles+\"glove.6B/glove.6B.50d.txt\", \n",
    "                                             word2vec_output_file = outputDir_Bigfiles+\"word2vec_glove_file\")\n",
    "size = str(round((os.path.getsize(outputDir_Bigfiles+\"word2vec_glove_file\")/1000000),1))\n",
    "print('Glove model size :'+size+ ' MB')\n",
    "# Load GloVe: Global Vectors for Word Representation Word2Vec model.\n",
    "glove_model = word2vec.KeyedVectors.load_word2vec_format(outputDir_Bigfiles+\"word2vec_glove_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cash', 0.8989869356155396), ('paying', 0.8788655996322632), ('funds', 0.8768925070762634), ('pay', 0.8716533184051514), ('raise', 0.8444491028785706)]\n",
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(glove_model.most_similar('money', topn=5))\n",
    "#find the odd one out\n",
    "print (glove_model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Google Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google model size :3644.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "google_model = word2vec.KeyedVectors.load_word2vec_format \\\n",
    "(inputDir_BigFiles+'GoogleNews_w2v/GoogleNews-vectors-negative300.bin', binary=True) \n",
    "size = str(round((os.path.getsize(inputDir_BigFiles+'GoogleNews_w2v/GoogleNews-vectors-negative300.bin')/1000000),1))\n",
    "print('Google model size :'+size+ ' MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Google Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(google_model.most_similar('money', topn=5))\n",
    "#find the odd one out\n",
    "print (google_model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
