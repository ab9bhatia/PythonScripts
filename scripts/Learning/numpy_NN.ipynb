{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data, target, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 120, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(test_X), len(train_y), len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idim = train_X[0].shape[0] #input layer\n",
    "hdim = 100  # no of neurons in hidden layer\n",
    "odim = len(np.unique(train_y))\n",
    "alpha =0.01 # Learning rate\n",
    "reg_lambda =0.01 # Regularization type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = {'W1':None,'b1':None,'W2':None,'b2':None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prop(model,x):\n",
    "    W1,b1,W2,b2 = model['W1'],model['b1'],model['W2'],model['b2']\n",
    "    z1 = x.dot(W1) + b1\n",
    "    a1 = np.tanh(a1) #activation function\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    exp_scores = np.exp(z2)\n",
    "    probs = exp_scores/np.sum()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(model,x):\n",
    "    probs = forward_prop(model,x)\n",
    "    targets = -np.log(probs[range(len(train_X)),train_y])\n",
    "    loss = np.sum(target)\n",
    "    loss += reg_lambda/2 * (np.sum(np.square(model['W1']))+ np.sum(np.square(model['W2'])))\n",
    "    return 1./len(train_x) * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model,x):\n",
    "    probs = forward_prop(model,x) # [0.1,0.2,0.7]\n",
    "    return np.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(model,x,y):\n",
    "    predictions = predict(model,x)\n",
    "    accuracy = np.sum(predictions==y)/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainer(hdim, epochs):\n",
    "    W1 = np.random.rand(idim,hdim)/np.sqrt(idim) # Assign random values to weights\n",
    "    b1 = np.zeros((1, hdim))\n",
    "    W2 = np.random.rand(hdim,odim)/np.sqrt(hdim)\n",
    "    b2 = np.zeros((1, odim))\n",
    "    \n",
    "    model = {'W1':W1,'b1':b1,'W2':W2,'b2':b2}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        z1 = train_X.dot(W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        exp_score = np.exp(z2)\n",
    "        probs = exp_score/np.sum(exp_scores, axis =1, keepdims=True)\n",
    "        \n",
    "        # Backpropagation\n",
    "        delta3 = probs\n",
    "        delta3[range(len(train_X)),train_y] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis =0,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2000\n",
      " 0.5000\n",
      " 0.6000\n",
      " 0.7000\n",
      " 1.0000\n",
      " 2.0000\n",
      " 3.0000\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "list = [0.2,0.5,0.6,0.7,1,2,3]\n",
    "T = torch.Tensor(list)\n",
    "print(T)\n",
    "print(type(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.000000014901161"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Variable data has to be a tensor, but got int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-0a9099fc0b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Variable data has to be a tensor, but got int"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1.,2.,3.,4.])\n",
    "y = torch.Tensor([1.,3.,5.,7.])\n",
    "x = autograd.Variable(2)\n",
    "y = autograd.Variable(3)\n",
    "\n",
    "z= x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
