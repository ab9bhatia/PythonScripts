{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a common complaint amongst film critics is   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>whew   this film oozes energy   the kind of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>steven spielberg s   amistad     which is bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>he has spent his entire life in an awful litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>being that it is a foreign language film with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      1   a common complaint amongst film critics is   ...\n",
       "1      1   whew   this film oozes energy   the kind of b...\n",
       "2      1   steven spielberg s   amistad     which is bas...\n",
       "3      1   he has spent his entire life in an awful litt...\n",
       "4      1   being that it is a foreign language film with..."
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('movie_review_train.csv')\n",
    "X_test = pd.read_csv('movie_review_test.csv')\n",
    "X_train['class'] = X_train['class'].map({'Neg':0, 'Pos':1})\n",
    "X_test['class'] = X_test['class'].map({'Neg':0, 'Pos':1})\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.fit(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35858"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1\n",
    "X_train_vocabs_dict = dict.get_feature_names()\n",
    "len(X_train_vocabs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2\n",
    "dict2 = CountVectorizer(stop_words='english',min_df=.03,max_df=.8)\n",
    "dict2.fit(X_train['text'])\n",
    "len(dict2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51663"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3\n",
    "test = dict2.transform(X_test['text'])\n",
    "test.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albeit\n",
      "wide\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "print(dict2.get_feature_names()[49])\n",
    "print(dict2.get_feature_names()[-50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q5\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB()\n",
    "\n",
    "dict3 = CountVectorizer(stop_words='english',min_df=.03,max_df=.8)\n",
    "xTrain = dict3.fit_transform(X_train['text'])\n",
    "xTarget = X_train['class']\n",
    "yTrain = dict3.transform(X_test['text'])\n",
    "y_test = X_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.fit(xTrain,xTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NB.predict(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82750000000000001"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,  28],\n",
       "       [ 41, 159]], dtype=int64)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.flatten == f4.flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q7\n",
    "The scikit learn implementation of Naive Bayes counts the number of times each word appears in each class. The feature_count_  attribute of MultinomialNB object returns an array of  shape (n_classes, n_features). Rows represent classes, columns represent words. How many total words are there in positive reviews which are part of dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153000.0"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count=NB.feature_count_.sum(axis=1)\n",
    "word_count[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q8\n",
    "What is the count of total words in negative reviews which are part of the dictionary (note that all those words which don't belong to the dictionary are already ignored by default)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137807.0"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q9\n",
    "How many times does the word “stupid” appear in Negative reviews?\n",
    "\n",
    "You can use the get_feature_names() method of CountVectorizer() to get the list of words in vocab, and use the “feature_count_” attribute of an object of MultinomialNB() class to get the counts of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    161.0\n",
       "pos     35.0\n",
       "Name: stupid, dtype: float64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens = dict3.get_feature_names()\n",
    "neg = NB.feature_count_[0,:]\n",
    "pos = NB.feature_count_[1,:]\n",
    "\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'neg':neg, 'pos':pos}).set_index('token')\n",
    "tokens.loc['stupid', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q10 In Multinomial Naive Bayes, the probability of every word of the dictionary for each class is calculated by the classifier. For calculating the probability of a word in a given class the word count of that word for each class is calculated. Then it is divided by the total no of words present in that class which belong to the dictionary. What is the probability of word “painfully”  for positive class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerator 10.0\n",
      "denominator 153000.0\n"
     ]
    }
   ],
   "source": [
    "# convert the neg and pos counts into frequencies\n",
    "tokens['prob_neg'] = tokens.neg / word_count[0]\n",
    "tokens['prob_pos'] = tokens.pos / word_count[1]\n",
    "print('numerator',tokens.loc['painfully', ]['pos'])\n",
    "print('denominator',word_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q11 What is the most negative word in our training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>NbyP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>91.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>6.735507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfunny</th>\n",
       "      <td>60.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6.661490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasted</th>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>6.185670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lame</th>\n",
       "      <td>77.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>6.106366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridiculous</th>\n",
       "      <td>94.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>5.492808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             neg   pos  prob_neg  prob_pos      NbyP\n",
       "token                                               \n",
       "waste       91.0  15.0  0.000660  0.000098  6.735507\n",
       "unfunny     60.0  10.0  0.000435  0.000065  6.661490\n",
       "wasted      78.0  14.0  0.000566  0.000092  6.185670\n",
       "lame        77.0  14.0  0.000559  0.000092  6.106366\n",
       "ridiculous  94.0  19.0  0.000682  0.000124  5.492808"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['NbyP'] = tokens['prob_neg']/tokens['prob_pos']\n",
    "tokens.sort_values(by ='NbyP',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
