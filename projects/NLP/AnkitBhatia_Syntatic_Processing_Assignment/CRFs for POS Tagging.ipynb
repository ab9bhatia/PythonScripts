{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRFs for POS Tagging\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[Ankit Bhatia](https://www.linkedin.com/in/ab9bhatia/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<u>Summary</u>__\n",
    "Build a POS tagger using Conditional Random Fields\n",
    "\n",
    "HMM-based POS taggers do not use features, however, in a CRF based POS tagger, you can define rich feature functions which can deal with problems such as unknown words, complex word patterns etc. Also, in this part of the assignment, you will use three different tagged datasets for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install __sklearn_crfsuite__ using __\"pip install sklearn_crfsuite\" or \"conda install -c conda-forge python-crfsuite\"__\n",
    "2. Download all __NLTK__ modules using __nltk.download()__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn_crfsuite import metrics,scorers,CRF\n",
    "from nltk.tag.util import untag\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Treebank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "treebank = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in the corpus:: 3914 \n",
      "\n",
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print('Number of Sentences in the corpus::',len(treebank),'\\n')\n",
    "# print first two tagged sentences\n",
    "print(treebank[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Brown dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown = list(nltk.corpus.brown.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in the corpus:: 57340 \n",
      "\n",
      "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print('Number of Sentences in the corpus::',len(brown),'\\n')\n",
    "# print first two tagged sentences\n",
    "print(brown[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. CoNLL2000 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conll2000= list(nltk.corpus.conll2000.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in the corpus:: 10948 \n",
      "\n",
      "[[('Confidence', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('pound', 'NOUN'), ('is', 'VERB'), ('widely', 'ADV'), ('expected', 'VERB'), ('to', 'PRT'), ('take', 'VERB'), ('another', 'DET'), ('sharp', 'ADJ'), ('dive', 'NOUN'), ('if', 'ADP'), ('trade', 'NOUN'), ('figures', 'NOUN'), ('for', 'ADP'), ('September', 'NOUN'), (',', '.'), ('due', 'ADJ'), ('for', 'ADP'), ('release', 'NOUN'), ('tomorrow', 'NOUN'), (',', '.'), ('fail', 'VERB'), ('to', 'PRT'), ('show', 'VERB'), ('a', 'DET'), ('substantial', 'ADJ'), ('improvement', 'NOUN'), ('from', 'ADP'), ('July', 'NOUN'), ('and', 'CONJ'), ('August', 'NOUN'), (\"'s\", 'PRT'), ('near-record', 'ADJ'), ('deficits', 'NOUN'), ('.', '.')], [('Chancellor', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('Exchequer', 'NOUN'), ('Nigel', 'NOUN'), ('Lawson', 'NOUN'), (\"'s\", 'PRT'), ('restated', 'VERB'), ('commitment', 'NOUN'), ('to', 'PRT'), ('a', 'DET'), ('firm', 'NOUN'), ('monetary', 'ADJ'), ('policy', 'NOUN'), ('has', 'VERB'), ('helped', 'VERB'), ('to', 'PRT'), ('prevent', 'VERB'), ('a', 'DET'), ('freefall', 'NOUN'), ('in', 'ADP'), ('sterling', 'NOUN'), ('over', 'ADP'), ('the', 'DET'), ('past', 'ADJ'), ('week', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print('Number of Sentences in the corpus::',len(conll2000),'\\n')\n",
    "# print first two tagged sentences\n",
    "print(conll2000[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master = treebank + brown + conll2000\n",
    "#master = master[0:100] # Just for testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in the master corpus:: 72202 \n",
      "\n",
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print('Number of Sentences in the master corpus::',len(master),'\\n')\n",
    "# print first two tagged sentences\n",
    "print(master[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Build your CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset for training and testing\n",
    "cutoff = int(.80 * len(master))\n",
    "training_sentences = master[:cutoff]\n",
    "validation_sentences = master[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        X.append([features(untag(tagged), index) for index in range(len(tagged))])\n",
    "        y.append([tag for _, tag in tagged])\n",
    " \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57761\n",
      "14441\n",
      "Time Taken(Sec) in this cell 5.840530157089233\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_train, y_train = transform_to_dataset(training_sentences)\n",
    "X_valid, y_valid = transform_to_dataset(validation_sentences)\n",
    "print(len(X_train))     \n",
    "print(len(X_valid))\n",
    "end = time.time()\n",
    "print('Time Taken(Sec) in this cell',end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken(Sec) in this cell 739.0159306526184\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = CRF()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Time Taken(Sec) in this cell',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_tag(sentence):\n",
    "    sentence_features = [features(sentence, index) for index in range(len(sentence))]\n",
    "    return list(zip(sentence, model.predict([sentence_features])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRON'), ('am', 'VERB'), ('Learning', 'NOUN'), ('NLP', 'NOUN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['I','am','Learning','NLP']\n",
    "pos_tag(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Evaluate the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken(in Sec) in this cell 2.6693429946899414\n",
      "Accuracy:: 0.9438060158058392\n",
      "F1 Score 0.9435019419876269\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = model.predict(X_valid)\n",
    "end = time.time()\n",
    "print('Time Taken(in Sec) in this cell',end-start)\n",
    "print('Accuracy::',metrics.flat_accuracy_score(y_valid, y_pred))\n",
    "print('F1 Score',metrics.flat_f1_score(y_valid, y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .       1.00      1.00      1.00     41431\n",
      "        ADJ       0.85      0.87      0.86     20932\n",
      "        ADP       0.92      0.95      0.94     33697\n",
      "        ADV       0.91      0.92      0.91     12425\n",
      "       CONJ       0.99      1.00      0.99      8523\n",
      "        DET       0.92      0.96      0.94     29936\n",
      "       NOUN       0.96      0.95      0.96     89666\n",
      "        NUM       0.98      0.99      0.99     10567\n",
      "       PRON       0.94      0.79      0.86     11820\n",
      "        PRT       0.81      0.78      0.79     10669\n",
      "       VERB       0.96      0.96      0.96     47262\n",
      "          X       0.36      0.22      0.27       170\n",
      "\n",
      "avg / total       0.94      0.94      0.94    317098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_valid, y_pred, digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy from the base model is coming as ~94%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tune our model using gridsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "# parameters to tune\n",
    "params_space = {\n",
    "    'c1': [0.01, 0.1, 1],\n",
    "    'c2': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = scorers.make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted')\n",
    "\n",
    "rs = GridSearchCV(crf, \n",
    "                  params_space,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=2,\n",
    "                  scoring=f1_scorer, \n",
    "                  return_train_score=True)\n",
    "# fit\n",
    "#rs.fit(X_train, y_train) # Commented Explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "\n",
    "__[Parallel(n_jobs=2)]: Done  27 out of  27 | elapsed: 351.4min finished__\n",
    "\n",
    "GridSearchCV(cv=3, error_score='raise',\n",
    "       estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
    "  all_possible_transitions=True, averaging=None, c=None, c1=None, c2=None,\n",
    "  calibration_candidates=None, calibration_eta=None,\n",
    "  calibration_max_trials=None, calibration_rate=None,\n",
    "  calibration_samples=None, delta=None, epsilon=None, error...e,\n",
    "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
    "  variance=None, verbose=False),\n",
    "  \n",
    "    fit_params=None, iid=True, n_jobs=2,\n",
    "    \n",
    "    param_grid={'c1': [0.01, 0.1, 1], 'c2': [0.01, 0.1, 1]},\n",
    "    \n",
    "    pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
    "    scoring=make_scorer(flat_f1_score, average=weighted), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important:: It took approx 350 min to get the optimal hyperparameters, so I noted the best values of C1 & C2 and commented the above code, so that it will not take the time during code evaluation.\n",
    "\n",
    "__Note__ If you want to run the above code just uncomment __rs.fit(X_train, y_train)__ line\n",
    "\n",
    "\n",
    "### Let's thus choose c1 = 0.1 and c2 = 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store CV results in a DF\n",
    "#cv_results = pd.DataFrame(rs.cv_results_)\n",
    "#cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Rebuilding Model with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a model with optimal hyperparams\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pickle, we can save the model as a file so that it can be resued just by importing(without training the model again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "with open('Ankit_Bhatia_part_2.pkl', 'wb') as clf:\n",
    "    try:\n",
    "        cPickle.dump(crf, clf)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        clf.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Evaluate the Model Performance(after Hyperpatameters Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "import _pickle as cPickle\n",
    "\n",
    "with open('Ankit_Bhatia_part_2.pkl', 'rb') as fid:\n",
    "    crf = cPickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:: 0.946552800711452\n",
      "F1 Score 0.9463142916336001\n"
     ]
    }
   ],
   "source": [
    "# make predictions on validation data\n",
    "y_pred = crf.predict(X_valid)\n",
    "print('Accuracy::',metrics.flat_accuracy_score(y_valid, y_pred))\n",
    "print('F1 Score',metrics.flat_f1_score(y_valid, y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is just a slight difference in accuracy from 94.35% to 94.65%(using hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Testing Tuned Model on Sample Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Show', 'VERB'), ('me', 'PRON'), ('flights', 'VERB'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'ADP'), ('Nebraska', 'NOUN'), ('departing', 'VERB'), ('after', 'ADP'), ('8', 'NUM'), ('p.m.', 'ADV')]\n",
      "\n",
      "\n",
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'VERB'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('based', 'VERB'), ('on', 'ADP'), ('a', 'DET'), ('modified', 'VERB'), ('version', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('Linux', 'NOUN'), ('kernel.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'VERB'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013.', 'NUM')]\n",
      "\n",
      "\n",
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'PRON'), ('gave', 'VERB'), ('Google', 'ADJ'), ('access', 'NOUN'), ('to', 'ADP'), (\"Twitter's\", 'NOUN'), ('firehose.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'ADJ'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'VERB'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'VERB'), ('with', 'ADP'), ('messages', 'NOUN'), ('known', 'VERB'), ('as', 'ADP'), ('tweets.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('Before', 'ADP'), ('entering', 'VERB'), ('politics,', 'NOUN'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'ADJ'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup,', 'NOUN'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'ADJ'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('Show', 'VERB'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'ADJ'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'ADP'), ('Atlanta', 'NOUN')]\n",
      "\n",
      "\n",
      "[('I', 'PRON'), ('would', 'VERB'), ('like', 'VERB'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'ADP'), ('Philadelphia.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('Show', 'VERB'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADV'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco.', 'NOUN')]\n",
      "\n",
      "\n",
      "[('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'VERB'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite.', 'NOUN')]\n",
      "\n",
      "\n",
      "Time Taken(Sec) in this cell 206.9475667476654\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "test_sentences = [\"Show me flights from Denver to Nebraska departing after 8 p.m.\",\n",
    "                  \"Android is a mobile operating system developed by Google based on a modified version of the Linux kernel.\",\n",
    "                  \"Android is a mobile operating system developed by Google.\",\n",
    "                  \"Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.\",\n",
    "                  \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
    "                  \"Twitter is an online news and social networking service on which users post and interact with messages known as tweets.\",\n",
    "                  \"Before entering politics, Donald Trump was a domineering businessman and a television personality.\",\n",
    "                  \"The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\",\n",
    "                  \"This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.\",\n",
    "                  \"Show me the cheapest round trips from Dallas to Atlanta\",\n",
    "                  \"I would like to see flights from Denver to Philadelphia.\",\n",
    "                  \"Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.\",\n",
    "                  \"NASA invited social media users to experience the launch of ICESAT-2 Satellite.\"]\n",
    "\n",
    "\n",
    "#print(test_sentences)\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    sentence_features = [features(sentence, index) for index in range(len(sentence))]\n",
    "    return list(zip(sentence, crf.predict([sentence_features])[0]))\n",
    "\n",
    "for sentence  in test_sentences:\n",
    "    word_list = sentence.split(' ')\n",
    "    print(pos_tag(word_list)) \n",
    "    print(\"\\n\")\n",
    "end = time.time()\n",
    "print('Time Taken(Sec) in this cell',end-start)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Enlist Important State and Transition Features learnt by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .      0.997     0.999     0.998     41431\n",
      "        ADJ      0.861     0.883     0.872     20932\n",
      "        ADP      0.919     0.954     0.936     33697\n",
      "        ADV      0.902     0.922     0.912     12425\n",
      "       CONJ      0.992     0.997     0.994      8523\n",
      "        DET      0.922     0.957     0.939     29936\n",
      "       NOUN      0.969     0.953     0.961     89666\n",
      "        NUM      0.983     0.991     0.987     10567\n",
      "       PRON      0.941     0.800     0.865     11820\n",
      "        PRT      0.817     0.787     0.801     10669\n",
      "       VERB      0.962     0.967     0.965     47262\n",
      "          X      0.364     0.276     0.314       170\n",
      "\n",
      "avg / total      0.947     0.947     0.946    317098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_valid, y_pred,  digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common transitions:\n",
      "X     -> X      6.713\n",
      "ADJ   -> NOUN   4.159\n",
      "PRT   -> VERB   2.596\n",
      "PRON  -> VERB   2.256\n",
      "DET   -> NOUN   2.228\n",
      "NOUN  -> NOUN   2.118\n",
      "ADP   -> NOUN   2.075\n",
      "NOUN  -> PRON   2.066\n",
      "VERB  -> NOUN   2.012\n",
      "ADV   -> ADJ    1.957\n",
      "NOUN  -> VERB   1.744\n",
      "DET   -> ADJ    1.619\n",
      "ADJ   -> ADJ    1.545\n",
      "ADJ   -> NUM    1.455\n",
      "ADV   -> ADV    1.349\n",
      "VERB  -> ADV    1.321\n",
      "VERB  -> PRT    1.312\n",
      "X     -> VERB   1.304\n",
      "ADP   -> DET    1.292\n",
      "DET   -> VERB   1.185\n",
      "\n",
      "Top 10 Most Uncommon transitions:\n",
      "ADV   -> X      -1.280\n",
      "CONJ  -> NUM    -1.304\n",
      "ADP   -> .      -1.309\n",
      "X     -> ADP    -1.315\n",
      "X     -> NUM    -1.334\n",
      "DET   -> PRON   -1.406\n",
      "DET   -> DET    -1.445\n",
      "NUM   -> ADV    -1.466\n",
      "NUM   -> PRON   -1.508\n",
      "DET   -> .      -1.578\n",
      ".     -> NUM    -1.586\n",
      "NUM   -> DET    -1.799\n",
      "ADP   -> X      -1.838\n",
      "NUM   -> VERB   -2.075\n",
      "DET   -> CONJ   -2.205\n",
      "DET   -> PRT    -2.262\n",
      "DET   -> ADP    -2.269\n",
      "CONJ  -> CONJ   -2.685\n",
      "CONJ  -> X      -2.819\n",
      "CONJ  -> .      -3.574\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-5s -> %-6s %0.3f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top 10 Most Common transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop 10 Most Uncommon transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
